---
title: "Final project Group 7"
author: |
  | Bharath Reddy Madi
  | Prasanna Krishna Reddy Jeedipally
  | Divya Sharvani Kandukuri
date: "2022-12-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 

# Problem: Analysis of Employee Attrition(Employee Churn Prediction)

## Abstract:

A corporation may suffer from voluntary employee attrition in a number of ways, including increased labor costs, lowered employee morale, the loss of intellectual property and talent to rivals, etc. Therefore, it is crucial to spot each employee who has a propensity to leave the organization in order to prevent a future loss. Conventional procedures rely on qualitative evaluation of variables that may suggest an employee's propensity to leave a company. For instance, research has shown that staff turnover is related to both demographic data and behavioral activities, satisfaction, etc. Data-driven approaches that are based on statistical learning techniques show more accurate prediction of employee attrition because, by their very nature, they mathematically model the relationship between factors and attrition outcome and maximize the probability of predicting the right group of people using a properly trained machine learning model.

## Introduction:

Employee churn is described as a decision made voluntarily by an employee to leave their employment or retire, necessitating the hiring of a new applicant. People frequently leave their jobs for a variety of reasons, including a feeling of lacking coaching and feedback, a lack of growth, commuting time, an unsatisfactory pay scale, a sense of devaluation, work stress, a lack of balance between work and life, a lack of trust in their boss, etc. According to a survey released by LinkedIn Talent Solutions in 2018, the IT sector leads all other sectors with a 13.2% employee turnover rate. We created four different models, one using Boosted Logistic Regression, Support Vector Machine, Random Forest, and the stack of all the above models, to optimize the performance of the models we used to predict whether an employee will leave or not in order to address the employee turnover issue. We explored and cleaned the IBM HR dataset that we downloaded from www.kaagle.com. We perfrmed feature selection in order to use only attributes that helps in model prediction. Employees are traditionally seen as important company assets. The best performers and especially those who have worked for a longer period of time are regarded as special employees. Compared to regular employees, businesses suffer more loss when exceptional employees opt to leave. When a senior and knowledgeable person leaves, it can have a psychological impact on the team, which lowers team morale.

## Data Description:

### Dataset:

Source-\> <https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset>

This is a fictional data set created by IBM data scientists.

#### Attributes in the dataset: There are total 35 attributes in the dataset

The dimensions of the data set is 1470 \* 35

The attributes are:

    1 "Age"                      
    2 "Attrition"                
    3 "BusinessTravel"          
    4 "DailyRate"                
    5 "Department"               
    6 "DistanceFromHome"        
    7 "Education"                
    8 "EducationField"           
    9 "EmployeeCount"           
    10 "EmployeeNumber"           
    11 "EnvironmentSatisfaction"  
    12 "Gender"                  
    13 "HourlyRate"               
    14 "JobInvolvement"           
    15 "JobLevel"                
    16 "JobRole"                  
    17 "JobSatisfaction"          
    18 "MaritalStatus"           
    19 "MonthlyIncome"            
    20 "MonthlyRate"              
    21 "NumCompaniesWorked"      
    22 "Over18"                   
    23 "OverTime"                 
    24 "PercentSalaryHike"       
    25 "PerformanceRating"        
    26 "RelationshipSatisfaction" 
    27 "StandardHours"           
    28 "StockOptionLevel"         
    29 "TotalWorkingYears"        
    30 "TrainingTimesLastYear"   
    31 "WorkLifeBalance"          
    32 "YearsAtCompany"           
    33 "YearsInCurrentRole"      
    34 "YearsSinceLastPromotion"  
    35 "YearsWithCurrManager" 

1\. Data-driven analytics for HR attrition prediction

```{r}
# importing all the required libraries required for our project

library(dplyr)
library(magrittr)
library(stringr)
library(stringi)
library(readr)
library(DMwR2)
library(caret)
library(caretEnsemble)
library(pROC)
library(httr)
library(scales)
library(ggplot2)
library(wordcloud)
     
```

```{r}
#reading the dataset
DATA1 <- "/Employee_attrition.csv"
```

```{r}
#storing the data in the dataframe
df <- read_csv("Employee_attrition.csv")
     
```

```{r}
#Displaying top 5 rows of the dataframe
head(df)

```

```{r}
#Displaying the dimensions of the data frame
dim(df)
```

```{r}
#Displaying the column names of the data frame
names(df)

```

```{r}
str(df)
```

#### 2 Visualization of data

### Data Visualization:

The basic objectives of data visualization are to extract and transform huge volumes of complex information into a visual environment, such as a graph or chart, and to facilitate understanding or interpretation of this information. When presented as figures or spreadsheets, data can be challenging to analyze, especially when presented in huge volumes. Complex datasets are converted into a combination of understandable graphics and information via data visualization. The capacity to quickly convey information to an audience and enable them to determine outcomes or develop predictions in light of the interpreted facts. The use of effective data visualizations allows marketing teams to assess their results swiftly and move on to other campaigns or ideas.

The capacity to concisely and clearly illustrate complicated data linkages. As a result, graphs and charts feature distinct headings and descriptions that provide a streamlined study of vast volumes of complex data.

Initial exploratory analysis can be performed to understand the data set. For example,

1.  the proportion of employees with different job titles (or any other possible factor) for status of "attrition" and "non-attrition" may vary, and this can be plotted as follows. People titled "Laboratory Technician", "Sales Executive", and "Research Scientist" are among the top 3 groups that exhibit highest attrition rate.

```{r}
#Visualization of the data
#ggplot is based on the grammar of Graphics

ggplot(df, aes(JobRole, fill=Attrition)) +
  geom_bar(aes(y=(..count..)/sum(..count..)), position="dodge") +
  scale_y_continuous(labels=percent) +
  xlab("Job Role") +
  ylab("Percentage")
     

```

2.  monthly income, job level, and service year may affect decision of leaving for employees in different departments. For example, junior staffs with lower pay will be more likely to leave compared to those who are paid higher.

```{r}
ggplot(filter(df, (YearsAtCompany >= 2) & (YearsAtCompany <= 5) & (JobLevel < 3)),
       aes(x=factor(JobRole), y=MonthlyIncome, color=factor(Attrition))) +
  geom_boxplot() +
  xlab("Department") +
  ylab("Monthly income") +
  scale_fill_discrete(guide=guide_legend(title="Attrition")) +
  theme_bw() +
  theme(text=element_text(size=13), legend.position="top")


```

3.  Promotion is a commonly adopted HR strategy for employee retention. It can be observed in the following plot that for a certain department, e.g., Research & Development, employees with higher job level is more likely to leave if there are years since their last promotion.

```{r}
ggplot(filter(df, as.character(Attrition) == "Yes"), aes(x=YearsSinceLastPromotion)) +
  geom_histogram(binwidth=0.5) +
  aes(y=..density..) +
  xlab("Years since last promotion.") +
  ylab("Density") +
  # scale_fill_discrete(guide=guide_legend(title="Attrition")) +
  facet_grid(Department ~ JobLevel)
```

Density graphs displaying the department wise promotion year wise. There are three departments, sales, Research and development, and Human resources.

#### Data pre-processing

Data preprocessing is the process of removing unwanted data from the dataset, making the data balance, removing the noise and outliers and handling the missing data.

```{r}
# obtaining predictors that has no variation

pred_no_var <- names(df[, nearZeroVar(df)]) %T>% print()
```

```{r}

# removing the predictor columns with zero variation
df %<>% select(-one_of(pred_no_var))
```

Integer types of predictors which are nominal are converted to categorical type.

```{r}
# converting integer variable to factor

int_2_ftr_vars <- c("Education", "EnvironmentSatisfaction", "JobInvolvement", "JobLevel", "JobSatisfaction", "NumCompaniesWorked", "PerformanceRating", "RelationshipSatisfaction", "StockOptionLevel")

df[, int_2_ftr_vars] <- lapply((df[, int_2_ftr_vars]), as.factor)

```

The variables of character type are converted to categorical type.

\

```{r}
df %<>% mutate_if(is.character, as.factor)
```

```{r}
str(df)
```

## Materials and Methods

#### Problem formalization

A model for predicting attrition can be built once the data is well-prepared. To predict whether or not an employee will depart is known as a binary classification problem, which is how employee attrition prediction is typically classed. Person status, labeled as Attrition in the data set, is used in this research case to predict outcomes. It has two levels, Yes and No, depending on whether the employee has departed or not.

Check the label column to make sure it is a factor type, as the model to be built is a classifier.

```{r}
#Checks for categorical variable
is.factor(df$Attrition)
```

### Feature Selection

Given that not all variables are necessarily connected with the label, feature selection is done to eliminate those that are most important.Since the data set contains both discrete and numerical variables, some correlation analyses, such Pearson correlation, is not appropriate. One option is to train a model, rank the variables' importance, and then choose the most important ones.

The following shows how to achieve variable importance ranking with a random forest model.

```{r}
# set up the training control.

control <- trainControl(method="repeatedcv", number=3, repeats=1)

# train the model

model <- train(dplyr::select(df, -Attrition), 
               df$Attrition,
               data=df, 
               method="rf", 
               preProcess="scale", 
               trControl=control)
```

Now lets plot the importance graph from which we select our top features and drop the remaining from the dataset.

```{r}

# estimate variable importance

imp <- varImp(model, scale=FALSE)

# plot

plot(imp)
```

Here below we dropped the last 3 low ranking variables and we worked on remaining 29 features and the the target variable "Attrition".

```{r}
# select the top-ranking variables.

imp_list <- rownames(imp$importance)[order(imp$importance$Overall, decreasing=TRUE)]

# drop the low ranking variables. Here the last 3 variables are dropped. 

top_var <- 
  imp_list[1:(ncol(df) - 3)] %>%
  as.character() 

top_var
     
```

```{r}
# select the top ranking variables 

df %<>% select(., one_of(c(top_var, "Attrition")))
```

#### Splitting the data into train and test sets:

A prediction model can be then created for predictive analysis. The whole data is split into training and testing sets. The former is used for model creation while the latter for verification. We have split the data in 70:30 ratio.

Train data set consists of 70% of the dataset.

Test data set contains 30% of the dataset.

```{r}
train_index <- 
  createDataPartition(df$Attrition,
                      times=1,
                      p=.7) %>%
  unlist()

df_train <- df[train_index, ]
df_test <- df[-train_index, ]
     
```

One thing worthnoting is that the training set is not balanced, which may deteriorate the performance in training a model.

```{r}
table(df_train$Attrition)
```

There are more active employees (864) than terminated employees (166). The problem of data imbalance can be resolved in a number of ways:

Re-sampling the data, either to increase the minority class's representation or to decrease the majority class's.

Use cost sensitive learning method.

In the context of Imbalanced classes, the ROSE package contains routines to address binary classification issues. A binary classifier's estimation and accuracy evaluation phases can be aided in the presence of an uncommon class by using artificial balanced samples created using a smoothed bootstrap technique. There are further functions that implement more conventional solutions to the class imbalance as well as several metrics for accuracy evaluation. These are calculated using cross-validation, bootstrap, or holdout techniques.

```{r}

# note DMwR::SMOTE does not handle well with tbl_df. Need to convert to data frame.
library("smotefamily")
library(ROSE)
df_train %<>% as.data.frame()
#ROSE(admit~., data = train, N = 500, seed=111)$data
df_train <- ROSE(Attrition ~ .,
                 data=df_train,
                  N=1030,
                  seed=111)$data


```

```{r}
table(df_train$Attrition)
```

#### Models

After balancing the training set, a model can be created for prediction. For comparison purpose, different individual models, as well as ensemble of them, are trained on the data set.

1.  **Individual models.**

    1.1 Support vector machine with radial basis function kernel

    1.2 Random forest

    1.3 Boosted Logistic Regression

2.  **Stack of Models**

### 1.1 Support vector machine with radial basis function kernel

Support vector machines are a famous and a very strong classification technique which does not use any sort of probabilistic model like any other classifier but simply generates hyperplanes or simply putting lines, to separate and classify the data in some feature space into different regions.

```{r}


# initialize training control.  

tc <- trainControl(method="boot", 
                   number=3, 
                   repeats=3, 
                   search="grid",
                   classProbs=TRUE,
                   savePredictions="final",
                   summaryFunction=twoClassSummary)

# SVM model.

time_svm <- system.time(
  model_svm <- train(Attrition ~ .,
                     df_train,
                     method="svmRadial",
                     trainControl=tc)
)
```

### Random forest

The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction committee is more accurate than that of any individual tree

```{r}
# random forest model

time_rf <- system.time(
  model_rf <- train(Attrition ~ .,
                     df_train,
                     method="rf",
                     trainControl=tc)
)


```

### Boosted Logistic Regression

Boosting the logistic regression model is a way to convert a set of weak learners to a strong model. The weak learners specialize on different subsets of data. The subsequent models will do the classification task on the misclassified data. The final model can be a weighted sum of your weak models. With boosting, you can get better results since it can reduce bias as well as variance.

```{r}
#Boosted Logistic Regression
ctrl <- trainControl(method = "repeatedcv",
                        number = 4,
                        savePredictions = TRUE,
                        verboseIter = T,
    
                                         returnResamp = "all")
time_logit <- system.time(
  model_logit <- train(Attrition ~ .,
                     df_train,
                     method="LogitBoost",
                     family="binomial",
                     trainControl=ctrl))

```

### Stack of Models

Model Stacking is a way to improve model predictions by combining the outputs of multiple models that we modeled above and running them through as another machine learning model called a meta-learner. Thismodel has given the highest accuracy amongst the other three models. This is a kind of ensembling technique.

```{r}
time_ensemble <- system.time(
  model_list <- caretList(Attrition ~ ., 
                          data=df_train,
                          trControl=tc,
                          methodList=c("svmRadial", "rf","LogitBoost"
                                       ))
)
```

```{r}

# stack of models. Use glm for meta model.

model_stack <- caretStack(
  model_list,
  metric="ROC",
  method="glm",
  trControl=trainControl(
    method="boot",
    number=10,
    savePredictions="final",
    classProbs=TRUE,
    summaryFunction=twoClassSummary
  )
)

```

#### Model Validations

The trained models are applied on testing data sets for model evaluation.

```{r}
models <- list(model_svm, model_rf, model_stack,model_logit)

predictions <-lapply(models, 
                     predict, 
                     newdata=select(df_test, -Attrition))

     
```

```{r}
cm_metrics <- lapply(predictions,
                     confusionMatrix, 
                     reference=df_test$Attrition, 
                     positive="Yes")
cm_metrics
```

### Results

Here we have calculated accuracy, recall and precision for all our models and mapped them into a data frame for easier understanding at a glance.

```{r}
# accuracy

acc_metrics <- 
  lapply(cm_metrics, `[[`, "overall") %>%
  lapply(`[`, 1) %>%
  unlist()

# recall

rec_metrics <- 
  lapply(cm_metrics, `[[`, "byClass") %>%
  lapply(`[`, 1) %>%
  unlist()
  
# precision

pre_metrics <- 
  lapply(cm_metrics, `[[`, "byClass") %>%
  lapply(`[`, 3) %>%
  unlist()

algo_list <- c("SVM RBF", "Random Forest", "Stacking"," Boosted Logistic Regression")
time_consumption <- c(time_svm[3], time_rf[3], time_ensemble[3],time_logit[3])

df_comp <- 
  data.frame(Models=algo_list, 
             Accuracy=acc_metrics, 
             Recall=rec_metrics, 
             Precision=pre_metrics,
             Time=time_consumption) %T>%
             {head(.) %>% print()}

```

### Conclusion

Employee attrition is one of the major issues faced by firms of small, large and medium scale. Losing valuable employees because of the lack of insights into their satisfaction and factors which contribute to the resignation/retirement can be a big loss to the firms. Through our project, we tried to address this issue by leveraging data and statistical models. We used advanced statistical models like SVM, Random Forest, Boosted Logistic Regression and Stacking to try to predict with higher accuracy , which employees are more likely to leave the firm. We also observed that all models performed well, but Stacking gave the best results on our data. Due to lack of volume of data, we ran into a number of problems which we tried to address through resampling. Future prospects of this project would include acquiring larger volumes of data so that we can achieve higher accuracy and precision in our predictions.

**Author contributions:**

Prasanna Krishna Reddy Jeedipally: Data Cleaning, preprocessing and visualization

Bharath Reddy Madi: Implemented Boosted logistic regression, random forest and stack of models

Divya Sharvani Kandukuri: Implemented SVM with radial kernel and performed model validations.

#### We have pushed our project into Github repository.

Repository Link: <https://github.com/bharathrmadi/SDM1.git>
